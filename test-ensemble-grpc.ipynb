{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4651a40c",
   "metadata": {},
   "source": [
    "### Query an Ensemle model with Triton on gRPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f6cb540-0b9e-42f3-8adb-6d21e8fa6e08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip -q install tritonclient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01ec54e7-5371-480c-8677-1858dc5ed8a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports and parameters (adapt to your endpoint and model)\n",
    "import numpy as np\n",
    "import tritonclient.grpc as grpcclient\n",
    "import subprocess\n",
    "\n",
    "host = \"ensemble-kserve-triton-ensemble.apps.cluster-kgqjf.dynamic.redhatworkshops.io\"\n",
    "port = 443\n",
    "ssl_connection = True\n",
    "model_name = 'ensemble_merger_google_xgb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dc1a36e-d88b-485f-bbda-646540790a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case of self-signed certificate we need to fetch the certificate chain\n",
    "def save_cert_chain(url, port, filename):\n",
    "    # Run the OpenSSL command to get the certificate chain\n",
    "    command = f\"echo | openssl s_client -showcerts -connect {url}:{port} 2>/dev/null | openssl x509 -outform PEM > {filename}\"\n",
    "    subprocess.run(command, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa0ad3dd-9376-43e0-84b4-e15a1292a95b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize client\n",
    "if ssl_connection:\n",
    "    save_cert_chain(host, 443, 'cert_chain.pem')\n",
    "    root_certificates = 'cert_chain.pem'\n",
    "else:\n",
    "    root_certificates = None\n",
    "\n",
    "triton_client = grpcclient.InferenceServerClient(\n",
    "    url=host,\n",
    "    ssl=ssl_connection,\n",
    "    root_certificates=root_certificates,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c4d8be7-8bc3-402d-8ddc-ca28e708da6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tritonclient.grpc._infer_input.InferInput at 0x7f0834a9dbb0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare input and output objects\n",
    "inputs = []\n",
    "outputs = []\n",
    "inputs.append(grpcclient.InferInput(\"INPUT\", [1, 63], \"FP32\"))\n",
    "outputs.append(grpcclient.InferRequestedOutput(\"OUTPUT\"))\n",
    "\n",
    "# Create an array of 63 random floats between 0 and 1\n",
    "input_data = np.arange(start=0, stop=63, dtype=np.float32)\n",
    "\n",
    "# Expand the input into a batch (size=1)\n",
    "input_data = np.expand_dims(input_data, axis=0)\n",
    "\n",
    "# Initialize the data\n",
    "inputs[0].set_data_from_numpy(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a30e1c62-d6a7-4820-82bf-c403d04d5ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the inference request\n",
    "results = triton_client.infer(\n",
    "        model_name=model_name,\n",
    "        inputs=inputs,\n",
    "        outputs=outputs,\n",
    "        headers={\"test\": \"1\"},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71176beb-3ecc-4f13-bd15-66e49d68449f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.8066086e+03,  2.8076086e+03,  1.0000000e+00,  0.0000000e+00,\n",
       "         1.0000000e+00,  0.0000000e+00,  1.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get and display results\n",
    "output_data = results.as_numpy(\"OUTPUT\")\n",
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2a27a17-7c6b-4d22-9c44-08d51acf57ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_stats {\n",
      "  name: \"ensemble_merger_google_xgb\"\n",
      "  version: \"1\"\n",
      "  last_inference: 1709756530871\n",
      "  inference_count: 5\n",
      "  execution_count: 5\n",
      "  inference_stats {\n",
      "    success {\n",
      "      count: 5\n",
      "      ns: 87987477\n",
      "    }\n",
      "    fail {\n",
      "    }\n",
      "    queue {\n",
      "      count: 5\n",
      "      ns: 19785\n",
      "    }\n",
      "    compute_input {\n",
      "      count: 5\n",
      "      ns: 1393285\n",
      "    }\n",
      "    compute_infer {\n",
      "      count: 5\n",
      "      ns: 78572193\n",
      "    }\n",
      "    compute_output {\n",
      "      count: 5\n",
      "      ns: 3233917\n",
      "    }\n",
      "    cache_hit {\n",
      "    }\n",
      "    cache_miss {\n",
      "    }\n",
      "  }\n",
      "  batch_stats {\n",
      "    batch_size: 1\n",
      "    compute_input {\n",
      "      count: 5\n",
      "      ns: 1393285\n",
      "    }\n",
      "    compute_infer {\n",
      "      count: 5\n",
      "      ns: 78572193\n",
      "    }\n",
      "    compute_output {\n",
      "      count: 5\n",
      "      ns: 3233917\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get and display statistics from the server\n",
    "statistics = triton_client.get_inference_statistics(model_name=model_name)\n",
    "print(statistics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
